{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Response Prediction Using an MLP Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from cdrpy.data import Dataset\n",
    "from cdrpy.data.preprocess import normalize_responses\n",
    "from cdrpy.mapper import BatchedResponseGenerator\n",
    "from cdrpy.metrics import tf_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1771"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation\n",
    "\n",
    "### Loading the drug response dataset\n",
    "\n",
    "We can load a saved `cdrpy` datasest using the `Dataset.load` method. This demo dataset consists of harmonized cell line pharmacogenomic data retreived from the **Genomics of Drug Sensitivity in Cancer** and the **Cell Model Passports** data resources.\n",
    "\n",
    "In this dataset, cell lines are represented by log-transformed TPM gene expression values for 1771 cancer-relevant genes. Drugs are represented as 512 bit Morgan Fingerprints. Drug responses correspond to the natural log of the half-maximal inhibitory concentration (ln(IC50)) values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(name=CellModelPassportsGDSCv2, size=131_847, n_cells=792, n_drugs=184)\n"
     ]
    }
   ],
   "source": [
    "D = Dataset.load(\"../../data/datasets/temp/demo.h5\")\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: add some data exploration -> how many features do we have\n",
    "# for expression and morgan fingerprints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data\n",
    "\n",
    "In precision oncology, we need to predict response in never-before-seen patients. To mimic this setting, we will use scikit-learn's `train_test_split` function to generate a train/test split in which all drug responses for a given cell line are held out for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_ids = D.cell_meta.index\n",
    "cell_groups = D.cell_meta[\"cancer_type\"]  # stratify by cancer type\n",
    "test_size = 0.1\n",
    "\n",
    "train_cell_ids, test_cell_ids = train_test_split(\n",
    "    cell_ids,\n",
    "    stratify=cell_groups,\n",
    "    test_size=test_size,\n",
    "    random_state=SEED,\n",
    ")\n",
    "\n",
    "train_cell_ids, val_cell_ids = train_test_split(\n",
    "    train_cell_ids,\n",
    "    stratify=cell_groups.loc[train_cell_ids],\n",
    "    test_size=test_size,\n",
    "    random_state=SEED,\n",
    ")\n",
    "\n",
    "train_ds = D.select_cells(train_cell_ids, name=\"train\")\n",
    "val_ds = D.select_cells(val_cell_ids, name=\"val\")\n",
    "test_ds = D.select_cells(test_cell_ids, name=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "To avoid data leakage, several preprocessing steps should be completed *after* splitting the data in train/validation/test sets.\n",
    "\n",
    "In this case, we will use scikit-learn's `StandardScaler` class to normalize gene expression values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge_data = train_ds.cell_encoders[\"exp\"].data\n",
    "\n",
    "ge_scaler = StandardScaler().fit(ge_data.loc[train_cell_ids])\n",
    "ge_data[:] = ge_scaler.transform(ge_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to normalize the raw drug response observations. `cdrpy` provides the `normalize_responses` helper function for this purpose. This function accepts an optional parameter, `norm_method`. When `norm_method` is set to `global`, normalization is performed per drug, reducing bias in overall performance estimates by variability in removing drug-specific effective concentration range from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = normalize_responses(\n",
    "    train_ds, val_ds, test_ds, norm_method=\"grouped\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating the model\n",
    "\n",
    "As an example, we will construct a simple model using three multi-layer perceptrons (MLPs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge_input_dim = train_ds.cell_encoders[\"exp\"].shape[-1]\n",
    "fp_input_dim = train_ds.drug_encoders[\"mol\"].shape[-1]\n",
    "\n",
    "x_ge = ge_input = keras.Input((ge_input_dim,))\n",
    "x_ge = keras.layers.Dense(128, activation=\"relu\")(x_ge)\n",
    "x_ge = keras.layers.Dense(64, activation=\"relu\")(x_ge)\n",
    "\n",
    "x_fp = fp_input = keras.Input((fp_input_dim,))\n",
    "x_fp = keras.layers.Dense(128, activation=\"relu\")(x_fp)\n",
    "x_fp = keras.layers.Dense(64, activation=\"relu\")(x_fp)\n",
    "\n",
    "x = keras.layers.Concatenate()([x_ge, x_fp])\n",
    "x = keras.layers.Dense(64, activation=\"relu\")(x)\n",
    "x = keras.layers.Dense(32, activation=\"relu\")(x)\n",
    "x_out = keras.layers.Dense(1, activation=\"linear\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_19 (InputLayer)          [(None, 1771)]       0           []                               \n",
      "                                                                                                  \n",
      " input_20 (InputLayer)          [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 128)          226816      ['input_19[0][0]']               \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 128)          65664       ['input_20[0][0]']               \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 64)           8256        ['dense_25[0][0]']               \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 64)           8256        ['dense_27[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 128)          0           ['dense_26[0][0]',               \n",
      "                                                                  'dense_28[0][0]']               \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, 64)           8256        ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " dense_30 (Dense)               (None, 32)           2080        ['dense_29[0][0]']               \n",
      "                                                                                                  \n",
      " dense_31 (Dense)               (None, 1)            33          ['dense_30[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 319,361\n",
      "Trainable params: 319,361\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Model([ge_input, fp_input], x_out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-4),\n",
    "    loss=\"mean_squared_error\",\n",
    "    metrics=[tf_metrics.pearson],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = BatchedResponseGenerator(D, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = generator.flow_from_dataset(train_ds, shuffle=True, seed=SEED)\n",
    "val_gen = generator.flow_from_dataset(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=50, restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "834/834 - 6s - loss: 2.9188 - pearson: 0.7546 - val_loss: 1.9598 - val_pearson: 0.7117 - 6s/epoch - 8ms/step\n",
      "Epoch 2/50\n",
      "834/834 - 5s - loss: 1.6911 - pearson: 0.8759 - val_loss: 1.9248 - val_pearson: 0.7092 - 5s/epoch - 6ms/step\n",
      "Epoch 3/50\n",
      "834/834 - 5s - loss: 1.6049 - pearson: 0.8825 - val_loss: 1.8672 - val_pearson: 0.7121 - 5s/epoch - 5ms/step\n",
      "Epoch 4/50\n",
      "834/834 - 5s - loss: 1.5489 - pearson: 0.8865 - val_loss: 1.8537 - val_pearson: 0.7186 - 5s/epoch - 5ms/step\n",
      "Epoch 5/50\n",
      "834/834 - 5s - loss: 1.4951 - pearson: 0.8909 - val_loss: 1.8119 - val_pearson: 0.7183 - 5s/epoch - 6ms/step\n",
      "Epoch 6/50\n",
      "834/834 - 5s - loss: 1.4375 - pearson: 0.8955 - val_loss: 1.8577 - val_pearson: 0.7222 - 5s/epoch - 5ms/step\n",
      "Epoch 7/50\n",
      "834/834 - 5s - loss: 1.4015 - pearson: 0.8978 - val_loss: 1.8021 - val_pearson: 0.7257 - 5s/epoch - 5ms/step\n",
      "Epoch 8/50\n",
      "834/834 - 5s - loss: 1.3788 - pearson: 0.8993 - val_loss: 1.8927 - val_pearson: 0.7258 - 5s/epoch - 6ms/step\n",
      "Epoch 9/50\n",
      "834/834 - 5s - loss: 1.3587 - pearson: 0.9008 - val_loss: 1.8158 - val_pearson: 0.7235 - 5s/epoch - 5ms/step\n",
      "Epoch 10/50\n",
      "834/834 - 5s - loss: 1.3474 - pearson: 0.9022 - val_loss: 1.7948 - val_pearson: 0.7286 - 5s/epoch - 5ms/step\n",
      "Epoch 11/50\n",
      "834/834 - 5s - loss: 1.3072 - pearson: 0.9046 - val_loss: 1.8070 - val_pearson: 0.7225 - 5s/epoch - 5ms/step\n",
      "Epoch 12/50\n",
      "834/834 - 4s - loss: 1.2933 - pearson: 0.9060 - val_loss: 1.7632 - val_pearson: 0.7367 - 4s/epoch - 5ms/step\n",
      "Epoch 13/50\n",
      "834/834 - 5s - loss: 1.2678 - pearson: 0.9078 - val_loss: 1.7761 - val_pearson: 0.7338 - 5s/epoch - 5ms/step\n",
      "Epoch 14/50\n",
      "834/834 - 5s - loss: 1.2532 - pearson: 0.9093 - val_loss: 1.6995 - val_pearson: 0.7441 - 5s/epoch - 5ms/step\n",
      "Epoch 15/50\n",
      "834/834 - 5s - loss: 1.2249 - pearson: 0.9109 - val_loss: 1.7059 - val_pearson: 0.7418 - 5s/epoch - 6ms/step\n",
      "Epoch 16/50\n",
      "834/834 - 4s - loss: 1.2086 - pearson: 0.9118 - val_loss: 1.6902 - val_pearson: 0.7421 - 4s/epoch - 5ms/step\n",
      "Epoch 17/50\n",
      "834/834 - 4s - loss: 1.1865 - pearson: 0.9137 - val_loss: 1.6912 - val_pearson: 0.7458 - 4s/epoch - 5ms/step\n",
      "Epoch 18/50\n",
      "834/834 - 4s - loss: 1.1786 - pearson: 0.9148 - val_loss: 1.7512 - val_pearson: 0.7419 - 4s/epoch - 5ms/step\n",
      "Epoch 19/50\n",
      "834/834 - 5s - loss: 1.1612 - pearson: 0.9146 - val_loss: 1.6891 - val_pearson: 0.7467 - 5s/epoch - 5ms/step\n",
      "Epoch 20/50\n",
      "834/834 - 4s - loss: 1.1490 - pearson: 0.9162 - val_loss: 1.6654 - val_pearson: 0.7462 - 4s/epoch - 5ms/step\n",
      "Epoch 21/50\n",
      "834/834 - 4s - loss: 1.1418 - pearson: 0.9170 - val_loss: 1.7314 - val_pearson: 0.7398 - 4s/epoch - 5ms/step\n",
      "Epoch 22/50\n",
      "834/834 - 4s - loss: 1.1230 - pearson: 0.9184 - val_loss: 1.6570 - val_pearson: 0.7509 - 4s/epoch - 5ms/step\n",
      "Epoch 23/50\n",
      "834/834 - 4s - loss: 1.1141 - pearson: 0.9191 - val_loss: 1.6468 - val_pearson: 0.7534 - 4s/epoch - 5ms/step\n",
      "Epoch 24/50\n",
      "834/834 - 5s - loss: 1.1000 - pearson: 0.9203 - val_loss: 1.6569 - val_pearson: 0.7519 - 5s/epoch - 5ms/step\n",
      "Epoch 25/50\n",
      "834/834 - 4s - loss: 1.0969 - pearson: 0.9194 - val_loss: 1.6892 - val_pearson: 0.7510 - 4s/epoch - 5ms/step\n",
      "Epoch 26/50\n",
      "834/834 - 5s - loss: 1.0814 - pearson: 0.9214 - val_loss: 1.6947 - val_pearson: 0.7468 - 5s/epoch - 5ms/step\n",
      "Epoch 27/50\n",
      "834/834 - 4s - loss: 1.0688 - pearson: 0.9224 - val_loss: 1.6829 - val_pearson: 0.7482 - 4s/epoch - 5ms/step\n",
      "Epoch 28/50\n",
      "834/834 - 4s - loss: 1.0643 - pearson: 0.9226 - val_loss: 1.6713 - val_pearson: 0.7489 - 4s/epoch - 5ms/step\n",
      "Epoch 29/50\n",
      "834/834 - 4s - loss: 1.0723 - pearson: 0.9221 - val_loss: 1.6698 - val_pearson: 0.7537 - 4s/epoch - 5ms/step\n",
      "Epoch 30/50\n",
      "834/834 - 4s - loss: 1.0438 - pearson: 0.9245 - val_loss: 1.7049 - val_pearson: 0.7505 - 4s/epoch - 5ms/step\n",
      "Epoch 31/50\n",
      "834/834 - 4s - loss: 1.0425 - pearson: 0.9250 - val_loss: 1.6803 - val_pearson: 0.7506 - 4s/epoch - 5ms/step\n",
      "Epoch 32/50\n",
      "834/834 - 5s - loss: 1.0312 - pearson: 0.9254 - val_loss: 1.7230 - val_pearson: 0.7490 - 5s/epoch - 5ms/step\n",
      "Epoch 33/50\n",
      "834/834 - 4s - loss: 1.0277 - pearson: 0.9257 - val_loss: 1.7267 - val_pearson: 0.7528 - 4s/epoch - 5ms/step\n",
      "Epoch 34/50\n",
      "834/834 - 4s - loss: 1.0158 - pearson: 0.9264 - val_loss: 1.6559 - val_pearson: 0.7564 - 4s/epoch - 5ms/step\n",
      "Epoch 35/50\n",
      "834/834 - 5s - loss: 1.0119 - pearson: 0.9267 - val_loss: 1.6831 - val_pearson: 0.7520 - 5s/epoch - 5ms/step\n",
      "Epoch 36/50\n",
      "834/834 - 5s - loss: 1.0037 - pearson: 0.9278 - val_loss: 1.6890 - val_pearson: 0.7531 - 5s/epoch - 5ms/step\n",
      "Epoch 37/50\n",
      "834/834 - 5s - loss: 0.9915 - pearson: 0.9284 - val_loss: 1.6658 - val_pearson: 0.7526 - 5s/epoch - 6ms/step\n",
      "Epoch 38/50\n",
      "834/834 - 5s - loss: 0.9868 - pearson: 0.9288 - val_loss: 1.6883 - val_pearson: 0.7556 - 5s/epoch - 6ms/step\n",
      "Epoch 39/50\n",
      "834/834 - 4s - loss: 0.9820 - pearson: 0.9291 - val_loss: 1.7381 - val_pearson: 0.7495 - 4s/epoch - 5ms/step\n",
      "Epoch 40/50\n",
      "834/834 - 5s - loss: 0.9785 - pearson: 0.9295 - val_loss: 1.7622 - val_pearson: 0.7511 - 5s/epoch - 5ms/step\n",
      "Epoch 41/50\n",
      "834/834 - 5s - loss: 0.9701 - pearson: 0.9298 - val_loss: 1.7598 - val_pearson: 0.7449 - 5s/epoch - 5ms/step\n",
      "Epoch 42/50\n",
      "834/834 - 4s - loss: 0.9641 - pearson: 0.9304 - val_loss: 1.7028 - val_pearson: 0.7528 - 4s/epoch - 5ms/step\n",
      "Epoch 43/50\n",
      "834/834 - 5s - loss: 0.9513 - pearson: 0.9309 - val_loss: 1.6790 - val_pearson: 0.7524 - 5s/epoch - 5ms/step\n",
      "Epoch 44/50\n",
      "834/834 - 5s - loss: 0.9490 - pearson: 0.9313 - val_loss: 1.6566 - val_pearson: 0.7549 - 5s/epoch - 6ms/step\n",
      "Epoch 45/50\n",
      "834/834 - 5s - loss: 0.9436 - pearson: 0.9318 - val_loss: 1.7380 - val_pearson: 0.7474 - 5s/epoch - 5ms/step\n",
      "Epoch 46/50\n",
      "834/834 - 5s - loss: 0.9358 - pearson: 0.9321 - val_loss: 1.7100 - val_pearson: 0.7446 - 5s/epoch - 5ms/step\n",
      "Epoch 47/50\n",
      "834/834 - 5s - loss: 0.9365 - pearson: 0.9323 - val_loss: 1.6827 - val_pearson: 0.7520 - 5s/epoch - 5ms/step\n",
      "Epoch 48/50\n",
      "834/834 - 4s - loss: 0.9274 - pearson: 0.9331 - val_loss: 1.6851 - val_pearson: 0.7495 - 4s/epoch - 5ms/step\n",
      "Epoch 49/50\n",
      "834/834 - 4s - loss: 0.9221 - pearson: 0.9338 - val_loss: 1.6904 - val_pearson: 0.7525 - 4s/epoch - 5ms/step\n",
      "Epoch 50/50\n",
      "834/834 - 5s - loss: 0.9173 - pearson: 0.9337 - val_loss: 1.7010 - val_pearson: 0.7483 - 5s/epoch - 5ms/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_gen, epochs=50, validation_data=val_gen, verbose=2, callbacks=[early_stopping]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdrpy-tf-cpu-v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
