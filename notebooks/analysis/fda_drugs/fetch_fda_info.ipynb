{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch FDA approval annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import typing as t\n",
    "\n",
    "from bs4 import BeautifulSoup, Tag, NavigableString\n",
    "from getpass import getpass\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from pathlib import Path\n",
    "from urllib import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdsc_dir = Path(\"../../../data/processed/GDSC\")\n",
    "drug_info = pd.read_csv(\n",
    "    gdsc_dir / \"DrugAnnotations.csv\",\n",
    "    dtype={\"drug_id\": int, \"pubchem_id\": int},\n",
    ")\n",
    "drug_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = (\n",
    "    \"https://pubchem.ncbi.nlm.nih.gov/rest/pug_view/annotations/heading/JSON\"\n",
    ")\n",
    "\n",
    "\n",
    "def get_drugs_at_fda() -> t.Generator[dict, None, None]:\n",
    "    \"\"\"Downloads the PubCHEM Drugs@FDA annotations.\"\"\"\n",
    "    params = {\n",
    "        \"heading\": \"FDA Approved Drugs\",\n",
    "        \"heading_type\": \"Compound\",\n",
    "        \"page\": 1,\n",
    "        \"source\": \"Drugs@FDA\",\n",
    "    }\n",
    "    while True:\n",
    "        resp = requests.get(BASE_URL, params)\n",
    "        resp.raise_for_status()\n",
    "        annot = resp.json()[\"Annotations\"]\n",
    "        params[\"page\"] += 1\n",
    "        yield annot[\"Annotation\"]\n",
    "\n",
    "        if params[\"page\"] > annot[\"TotalPages\"]:\n",
    "            break\n",
    "\n",
    "\n",
    "def parse_drugs_at_fda(pages: t.Iterable[dict]) -> list[str]:\n",
    "    \"\"\"Extracts approved PubCHEM CIDs from Drugs@FDA annotations.\"\"\"\n",
    "    pchem_ids = []\n",
    "    for page in pages:\n",
    "        for annot in page:\n",
    "            records = annot.get(\"LinkedRecords\")\n",
    "            if records is not None:\n",
    "                linked_ids = records[\"CID\"]\n",
    "                pchem_ids.extend(linked_ids)\n",
    "    return sorted(list(set(pchem_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nci_cancer_drugs() -> t.Generator[dict, None, None]:\n",
    "    \"\"\"Downloads the PubCHEM NCI Cancer Drugs annotations.\"\"\"\n",
    "    params = {\n",
    "        \"heading\": \"Cancer Drugs\",\n",
    "        \"heading_type\": \"Compound\",\n",
    "        \"page\": 1,\n",
    "        \"source\": \"NCI Cancer Drugs\",\n",
    "    }\n",
    "    while True:\n",
    "        resp = requests.get(BASE_URL, params)\n",
    "        resp.raise_for_status()\n",
    "        annot = resp.json()[\"Annotations\"]\n",
    "        params[\"page\"] += 1\n",
    "        yield annot[\"Annotation\"]\n",
    "\n",
    "        if params[\"page\"] > annot[\"TotalPages\"]:\n",
    "            break\n",
    "\n",
    "\n",
    "def parse_nci_cancer_drugs(pages: t.Iterable[dict]) -> pd.DataFrame:\n",
    "    \"\"\"Extracts approved PubCHEM CIDs from Drugs@FDA annotations.\"\"\"\n",
    "    res = []\n",
    "    for page in pages:\n",
    "        for annot in page:\n",
    "            records = annot.get(\"LinkedRecords\")\n",
    "            data = annot.get(\"Data\")\n",
    "            if records is not None and data is not None:\n",
    "                linked_ids = records[\"CID\"]\n",
    "                indications = None\n",
    "                fda_status = None\n",
    "                for item in data:\n",
    "                    if \"Name\" in item:\n",
    "                        if item[\"Name\"] == \"FDA Approved\":\n",
    "                            fda = item[\"Value\"][\"StringWithMarkup\"][0][\n",
    "                                \"String\"\n",
    "                            ]\n",
    "                        elif item[\"Name\"] == \"Drug Use\":\n",
    "                            inds = item[\"Value\"][\"StringWithMarkup\"]\n",
    "                            inds = [x[\"String\"] for x in inds]\n",
    "                for id_ in linked_ids:\n",
    "                    res.append(\n",
    "                        {\n",
    "                            \"pubchem_id\": id_,\n",
    "                            \"NCICD__is_fda_approved\": fda == \"Yes\",\n",
    "                            \"NCICD__fda_indications\": inds,\n",
    "                            \"NCICD__url\": annot[\"URL\"],\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "    return pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Drugs@FDA annotations\n",
    "drugs_at_fda_annots = list(get_drugs_at_fda())\n",
    "drugs_at_fda_pchem_ids = parse_drugs_at_fda(drugs_at_fda_annots)\n",
    "drug_info[\"Drugs@FDA__is_fda_approved\"] = drug_info[\"pubchem_id\"].isin(\n",
    "    drugs_at_fda_pchem_ids\n",
    ")\n",
    "\n",
    "# add NCI Cancer Drugs annotations\n",
    "nci_cancer_drugs_annots = list(get_nci_cancer_drugs())\n",
    "nci_cancer_drugs_annots = parse_nci_cancer_drugs(nci_cancer_drugs_annots)\n",
    "drug_info = pd.merge(\n",
    "    drug_info, nci_cancer_drugs_annots, on=\"pubchem_id\", how=\"left\"\n",
    ")\n",
    "drug_info = drug_info.fillna({\"NCICD__is_fda_approved\": False})\n",
    "\n",
    "drug_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = (\n",
    "    r\"Using the following description, please extract a list of all approved \"\n",
    "    \"cancer types for {drug}. The result should be formatted as a list of \"\n",
    "    \"primary cancer type indications and, for each primary indication, a list \"\n",
    "    \"of cancer subtypes and/or sub-indications. The results should be in CSV \"\n",
    "    \"format as a string.\\n\\n\"\n",
    "    \"Description: \\\"{desc}\\\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_indication(items: list[str]) -> str:\n",
    "    parsed = \"\\n\".join(items)\n",
    "    parsed = parsed.replace(\".\", \". \")\n",
    "    return re.sub(\" +\", \" \", parsed).strip()\n",
    "    # for item in items:\n",
    "    #     item = item.replace(\"â€¢\", \" \")\n",
    "    #     item = item.replace(\":\", \" \")\n",
    "    #     item = re.sub(\"\\s+\", \" \", item)\n",
    "    #     parsed.append(item)\n",
    "    # return \" \".join(parsed).strip()\n",
    "\n",
    "\n",
    "drug_to_inds = (\n",
    "    drug_info[drug_info[\"NCICD__is_fda_approved\"] == True]\n",
    "    .dropna(subset=\"NCICD__fda_indications\")\n",
    "    .drop_duplicates(subset=\"pubchem_id\")\n",
    "    .filter(items=[\"drug_name\", \"pubchem_id\", \"NCICD__fda_indications\"])\n",
    ")\n",
    "drug_to_inds = dict(zip(temp[\"drug_name\"], temp[\"NCICD__fda_indications\"]))\n",
    "drug_to_prompt = {\n",
    "    k: template.format(drug=k, desc=parse_indication(v))\n",
    "    for k, v in drug_to_inds.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for drug, prompt in drug_to_prompt.items():\n",
    "    print(drug)\n",
    "    print(prompt)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\\n\".join(drug_to_inds[\"5-Fluorouracil\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(drug_to_prompt[\"5-Fluorouracil\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPENAI_API_KEY = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "drug = \"Cisplatin\"\n",
    "\n",
    "col = \"NCICD__fda_indications\"\n",
    "desc = drug_info[drug_info[\"drug_name\"] == drug].iloc[0][col]\n",
    "desc = parse_indication(desc)\n",
    "\n",
    "# prompt = template.format(drug=drug, desc=desc)\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"drug\", \"desc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = OpenAI(\n",
    "#     openai_api_key=\n",
    "# )\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "llm_chain.run(drug=drug, desc=desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4-0613\",\n",
    "    messages=[\n",
    "        {\"role\": \"assistant\", \"content\": template.format(drug=drug, desc=desc)}\n",
    "    ],\n",
    ")\n",
    "print(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "llm_chain.run(drug=drug, desc=desc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(template.format(drug=drug, description=desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "drug_info.to_csv(\n",
    "    gdsc_dir / \"DrugAnnotationsWithFDAApprovalStatus.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping NCI Cancer Drugs (DEPRECATED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = parse.urljoin(base_url, \"about-cancer/treatment/drugs\")\n",
    "resp = requests.get(url)\n",
    "soup = BeautifulSoup(resp.content, \"html.parser\")\n",
    "\n",
    "drug_lists = soup.find(\"article\").select(\"ul:not(nav ul)\")\n",
    "drug_to_link = {}\n",
    "for drug_list in drug_lists:\n",
    "    for a in drug_list.find_all(\"a\", href=True):\n",
    "        href = str(a[\"href\"])\n",
    "        if href.startswith(\"/about-cancer/treatment/drugs\"):\n",
    "            drug_name = a.text\n",
    "            drug_to_link[drug_name] = parse.urljoin(base_url, href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fda_status(article: Tag | NavigableString) -> str | None:\n",
    "    \"\"\"Extract FDA status from soup.\"\"\"\n",
    "    div = article.find(\"div\", string=\"FDA Approved\")\n",
    "    if div is not None:\n",
    "        fda_status = list(div.parent.children)[1].text\n",
    "        return fda_status\n",
    "\n",
    "\n",
    "def get_daily_mail_link(article: Tag | NavigableString) -> str | None:\n",
    "    \"\"\"Extract daily mail link from soup if present.\"\"\"\n",
    "    a = article.find(\"a\", {\"href\": re.compile(r\"dailymed\\.nlm\\.nih\\.gov\")})\n",
    "    if a is not None:\n",
    "        daily_mail_link = a[\"href\"]\n",
    "        return daily_mail_link\n",
    "\n",
    "\n",
    "def get_nci_drug_link(article: Tag | NavigableString) -> str | None:\n",
    "    \"\"\"Extract NCI drug dictionary link from soup if present.\"\"\"\n",
    "    pattern = re.compile(r\"publications\\/dictionaries\\/cancer-drug\")\n",
    "    a = article.find(\"a\", {\"href\": pattern})\n",
    "    if a is not None:\n",
    "        nci_drug_link = a[\"href\"]\n",
    "        return nci_drug_link\n",
    "    \n",
    "def get_cancer_types(article: Tag | NavigableString) -> list[str] | None:\n",
    "    \"\"\"Extract approved cancer types from soup.\"\"\"\n",
    "    h2 = article.find(\"h2\", string=\"Use in Cancer\")\n",
    "    if h2 is not None:\n",
    "        use_in_cancer_ul = h2.parent.find(\"ul\", recursive=False)\n",
    "        strongs = use_in_cancer_ul.find_all(\"strong\")\n",
    "        cancer_types = set()\n",
    "        if strongs is not None:\n",
    "            for el in strongs:\n",
    "                a = el.find(\"a\")\n",
    "                if a is not None:\n",
    "                    cancer_types.add(a.text)\n",
    "            return list(cancer_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_to_soup = {}\n",
    "for drug_name, drug_link in drug_to_link.items():\n",
    "    resp = requests.get(drug_link)\n",
    "    soup = BeautifulSoup(resp.content, \"html.parser\")\n",
    "    drug_to_soup[drug_name] = soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for drug_name, soup in drug_to_soup.items():\n",
    "    article = soup.find(\"article\")\n",
    "    if article is not None:\n",
    "        fda_status = get_fda_status(article)\n",
    "        nci_drug_link = get_nci_drug_link(article)\n",
    "        daily_mail_link = get_daily_mail_link(article)\n",
    "        cancer_types = get_cancer_types(article)\n",
    "        if cancer_types is None:\n",
    "            results.append(\n",
    "                [\n",
    "                    drug_name,\n",
    "                    None,\n",
    "                    fda_status,\n",
    "                    daily_mail_link,\n",
    "                    nci_drug_link,\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            for cancer_type in cancer_types:\n",
    "                results.append(\n",
    "                    [\n",
    "                        drug_name,\n",
    "                        cancer_type,\n",
    "                        fda_status,\n",
    "                        daily_mail_link,\n",
    "                        nci_drug_link,\n",
    "                    ]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(\n",
    "    results,\n",
    "    columns=[\n",
    "        \"drug_name\",\n",
    "        \"cancer_type\",\n",
    "        \"fda_status\",\n",
    "        \"daily_mail_link\",\n",
    "        \"nci_drug_dict_link\",\n",
    "    ],\n",
    ")\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(out_dir / \"FDAApprovedDrugCancerTypeCombos.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_list = results[[\"cancer_type\"]].drop_duplicates()\n",
    "cancer_list.to_csv(out_dir / \"CancerTypeList.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_list = results[[\"drug_name\", \"nci_drug_dict_link\"]].drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = drug_list[\"nci_drug_dict_link\"][0]\n",
    "resp = requests.get(link, allow_redirects=True)\n",
    "soup = BeautifulSoup(resp.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_list.to_csv(out_dir / \"DrugList.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdrpy-tf-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
